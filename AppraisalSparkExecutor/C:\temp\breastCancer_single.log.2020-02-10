2020-02-10 11:43:57 ERROR ImputationPlanRandomForestExec$:57 â Appraisal Spark - Wall start time: 10/02/2020 11:43:55
2020-02-10 11:43:57 ERROR ImputationPlanRandomForestExec$:58 â Parallel execution: false
2020-02-10 11:44:02 ERROR ImputationPlanRandomForestExec$:103 â Data count: 146
2020-02-10 11:45:03 ERROR ImputationPlanRandomForestExec$:57 â Appraisal Spark - Wall start time: 10/02/2020 11:45:02
2020-02-10 11:45:03 ERROR ImputationPlanRandomForestExec$:58 â Parallel execution: false
2020-02-10 11:45:09 ERROR ImputationPlanRandomForestExec$:103 â Data count: 146
2020-02-10 11:46:52 ERROR Instrumentation:70 â java.lang.IllegalArgumentException: DecisionTree requires size of input RDD > 0, but was given by empty one.
	at org.apache.spark.ml.tree.impl.DecisionTreeMetadata$$anonfun$8.apply(DecisionTreeMetadata.scala:113)
	at org.apache.spark.ml.tree.impl.DecisionTreeMetadata$$anonfun$8.apply(DecisionTreeMetadata.scala:113)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:112)
	at org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:106)
	at org.apache.spark.ml.regression.DecisionTreeRegressor$$anonfun$train$1.apply(DecisionTreeRegressor.scala:114)
	at org.apache.spark.ml.regression.DecisionTreeRegressor$$anonfun$train$1.apply(DecisionTreeRegressor.scala:104)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.DecisionTreeRegressor.train(DecisionTreeRegressor.scala:104)
	at org.apache.spark.ml.regression.DecisionTreeRegressor.train(DecisionTreeRegressor.scala:47)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.ensemble.HasBaseLearner$class.fitBaseLearner(ensembleParams.scala:115)
	at org.apache.spark.ml.regression.BaggingRegressor.fitBaseLearner(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2020-02-10 11:46:54 ERROR Instrumentation:70 â java.lang.IllegalArgumentException: DecisionTree requires size of input RDD > 0, but was given by empty one.
	at org.apache.spark.ml.tree.impl.DecisionTreeMetadata$$anonfun$8.apply(DecisionTreeMetadata.scala:113)
	at org.apache.spark.ml.tree.impl.DecisionTreeMetadata$$anonfun$8.apply(DecisionTreeMetadata.scala:113)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:112)
	at org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:106)
	at org.apache.spark.ml.regression.DecisionTreeRegressor$$anonfun$train$1.apply(DecisionTreeRegressor.scala:114)
	at org.apache.spark.ml.regression.DecisionTreeRegressor$$anonfun$train$1.apply(DecisionTreeRegressor.scala:104)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.DecisionTreeRegressor.train(DecisionTreeRegressor.scala:104)
	at org.apache.spark.ml.regression.DecisionTreeRegressor.train(DecisionTreeRegressor.scala:47)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.ensemble.HasBaseLearner$class.fitBaseLearner(ensembleParams.scala:115)
	at org.apache.spark.ml.regression.BaggingRegressor.fitBaseLearner(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2020-02-10 11:47:59 ERROR ImputationPlanRandomForestExec$:57 â Appraisal Spark - Wall start time: 10/02/2020 11:47:56
2020-02-10 11:47:59 ERROR ImputationPlanRandomForestExec$:58 â Parallel execution: false
2020-02-10 11:48:04 ERROR ImputationPlanRandomForestExec$:103 â Data count: 146
2020-02-10 11:50:17 ERROR ImputationPlanRandomForestExec$:57 â Appraisal Spark - Wall start time: 10/02/2020 11:50:16
2020-02-10 11:50:17 ERROR ImputationPlanRandomForestExec$:58 â Parallel execution: false
2020-02-10 11:50:22 ERROR ImputationPlanRandomForestExec$:103 â Data count: 146
2020-02-10 11:54:20 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 11:54:20 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:146)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:146)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:122)
	at appraisal.spark.algorithm.BaggingReg.run(BaggingRegressor.scala:111)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:319)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:314)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:314)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:104)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:102)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:102)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:395)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:91)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:89)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.engine.Crowner.runEnsemle(Crowner.scala:89)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec$.main(ImputationPlanRandomForestExec.scala:177)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec.main(ImputationPlanRandomForestExec.scala)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 11:54:20 ERROR ImputationPlan:370 â -------------------------------------
2020-02-10 11:54:20 ERROR ImputationPlan:370 â Running imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
2020-02-10 11:54:20 ERROR ImputationPlan:370 â Missing rate at 30.0% in feature bland_chromatin
2020-02-10 11:54:20 ERROR ImputationPlan:370 â Running Clustering[KMeans] | params: Map(k -> 4, kLimit -> 10, maxIter -> 1000, calcFeatures -> [Ljava.lang.String;@796d0b43)
2020-02-10 11:54:20 ERROR ImputationPlan:370 â ClusteringResult: ClusteringResult(MapPartitionsRDD[92] at map at KMeans.scala:44,4,260.48398766358264)
2020-02-10 11:54:20 ERROR ImputationPlan:370 â best k: 4
2020-02-10 11:54:20 ERROR ImputationPlan:370 â Batch for imputation after clustering strategy: 4
2020-02-10 11:54:20 ERROR ImputationPlan:370 â Batch for imputation before imputation strategy: 4
2020-02-10 11:54:20 ERROR ImputationPlan:370 â Running Imputation[BaggingRegressor] | params: Map(learningRate -> 0.1, k -> 5, imputationFeature -> bland_chromatin, kLimit -> 10, varianceComplete -> 3.9878025896040548, features -> [Ljava.lang.String;@78f9b1ec, calcFeatures -> [Ljava.lang.String;@796d0b43)
2020-02-10 11:54:20 ERROR ImputationPlan:371 â Error executing imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:146)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:146)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:122)
	at appraisal.spark.algorithm.BaggingReg.run(BaggingRegressor.scala:111)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:319)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:314)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:314)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:104)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:102)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:102)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:395)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:91)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:89)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.engine.Crowner.runEnsemle(Crowner.scala:89)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec$.main(ImputationPlanRandomForestExec.scala:177)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec.main(ImputationPlanRandomForestExec.scala)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more
2020-02-10 11:54:20 ERROR ImputationPlan:389 â -------------------------------------
2020-02-10 11:54:20 ERROR ImputationPlan:389 â Running imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
2020-02-10 11:54:20 ERROR ImputationPlan:389 â Missing rate at 30.0% in feature bland_chromatin
2020-02-10 11:54:20 ERROR ImputationPlan:389 â Running Clustering[KMeans] | params: Map(k -> 4, kLimit -> 10, maxIter -> 1000, calcFeatures -> [Ljava.lang.String;@796d0b43)
2020-02-10 11:54:20 ERROR ImputationPlan:389 â ClusteringResult: ClusteringResult(MapPartitionsRDD[92] at map at KMeans.scala:44,4,260.48398766358264)
2020-02-10 11:54:20 ERROR ImputationPlan:389 â best k: 4
2020-02-10 11:54:20 ERROR ImputationPlan:389 â Batch for imputation after clustering strategy: 4
2020-02-10 11:54:20 ERROR ImputationPlan:389 â Batch for imputation before imputation strategy: 4
2020-02-10 11:54:20 ERROR ImputationPlan:389 â Running Imputation[BaggingRegressor] | params: Map(learningRate -> 0.1, k -> 5, imputationFeature -> bland_chromatin, kLimit -> 10, varianceComplete -> 3.9878025896040548, features -> [Ljava.lang.String;@78f9b1ec, calcFeatures -> [Ljava.lang.String;@796d0b43)
2020-02-10 11:54:20 ERROR ImputationPlan:389 â Total plan execution time: 231 seconds, 3 minutes, 0 hours.
2020-02-10 11:54:20 ERROR Crowner:103 â Executed plans: 1 / 3 : 34%.
2020-02-10 11:56:39 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 12:58:13 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 12:58:13 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:146)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:146)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:122)
	at appraisal.spark.algorithm.BaggingReg.run(BaggingRegressor.scala:111)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:319)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:314)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:314)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:104)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:102)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:102)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:395)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:91)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:89)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.engine.Crowner.runEnsemle(Crowner.scala:89)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec$.main(ImputationPlanRandomForestExec.scala:177)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec.main(ImputationPlanRandomForestExec.scala)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 12:58:13 ERROR ImputationPlan:370 â -------------------------------------
2020-02-10 12:58:13 ERROR ImputationPlan:370 â Running imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
2020-02-10 12:58:13 ERROR ImputationPlan:370 â Missing rate at 30.0% in feature normal_nucleoli
2020-02-10 12:58:13 ERROR ImputationPlan:370 â Running Clustering[KMeans] | params: Map(k -> 4, kLimit -> 10, maxIter -> 1000, calcFeatures -> [Ljava.lang.String;@b513df1)
2020-02-10 12:58:13 ERROR ImputationPlan:370 â ClusteringResult: ClusteringResult(MapPartitionsRDD[2763] at map at KMeans.scala:44,4,218.47757575757615)
2020-02-10 12:58:13 ERROR ImputationPlan:370 â best k: 4
2020-02-10 12:58:13 ERROR ImputationPlan:370 â Batch for imputation after clustering strategy: 4
2020-02-10 12:58:13 ERROR ImputationPlan:370 â Batch for imputation before imputation strategy: 4
2020-02-10 12:58:13 ERROR ImputationPlan:370 â Running Imputation[BaggingRegressor] | params: Map(learningRate -> 0.1, k -> 5, imputationFeature -> normal_nucleoli, kLimit -> 10, varianceComplete -> 9.0838806530306, features -> [Ljava.lang.String;@78f9b1ec, calcFeatures -> [Ljava.lang.String;@b513df1)
2020-02-10 12:58:13 ERROR ImputationPlan:371 â Error executing imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:146)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:146)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:122)
	at appraisal.spark.algorithm.BaggingReg.run(BaggingRegressor.scala:111)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:319)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:314)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:314)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:104)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:102)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:102)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:395)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:91)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:89)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.engine.Crowner.runEnsemle(Crowner.scala:89)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec$.main(ImputationPlanRandomForestExec.scala:177)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec.main(ImputationPlanRandomForestExec.scala)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more
2020-02-10 12:58:13 ERROR ImputationPlan:389 â -------------------------------------
2020-02-10 12:58:13 ERROR ImputationPlan:389 â Running imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
2020-02-10 12:58:13 ERROR ImputationPlan:389 â Missing rate at 30.0% in feature normal_nucleoli
2020-02-10 12:58:13 ERROR ImputationPlan:389 â Running Clustering[KMeans] | params: Map(k -> 4, kLimit -> 10, maxIter -> 1000, calcFeatures -> [Ljava.lang.String;@b513df1)
2020-02-10 12:58:13 ERROR ImputationPlan:389 â ClusteringResult: ClusteringResult(MapPartitionsRDD[2763] at map at KMeans.scala:44,4,218.47757575757615)
2020-02-10 12:58:13 ERROR ImputationPlan:389 â best k: 4
2020-02-10 12:58:13 ERROR ImputationPlan:389 â Batch for imputation after clustering strategy: 4
2020-02-10 12:58:13 ERROR ImputationPlan:389 â Batch for imputation before imputation strategy: 4
2020-02-10 12:58:13 ERROR ImputationPlan:389 â Running Imputation[BaggingRegressor] | params: Map(learningRate -> 0.1, k -> 5, imputationFeature -> normal_nucleoli, kLimit -> 10, varianceComplete -> 9.0838806530306, features -> [Ljava.lang.String;@78f9b1ec, calcFeatures -> [Ljava.lang.String;@b513df1)
2020-02-10 12:58:13 ERROR ImputationPlan:389 â Total plan execution time: 3793 seconds, 63 minutes, 1 hours.
2020-02-10 12:58:13 ERROR Crowner:103 â Executed plans: 2 / 3 : 67%.
2020-02-10 13:01:37 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 15:26:26 ERROR ImputationPlanRandomForestExec$:57 â Appraisal Spark - Wall start time: 10/02/2020 15:26:24
2020-02-10 15:26:26 ERROR ImputationPlanRandomForestExec$:58 â Parallel execution: false
2020-02-10 15:26:32 ERROR ImputationPlanRandomForestExec$:103 â Data count: 146
2020-02-10 15:27:23 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 15:27:23 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:146)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:146)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:122)
	at appraisal.spark.algorithm.BaggingReg.run(BaggingRegressor.scala:112)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:319)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:314)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:314)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:104)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:102)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:102)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:395)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:91)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:89)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.engine.Crowner.runEnsemle(Crowner.scala:89)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec$.main(ImputationPlanRandomForestExec.scala:177)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec.main(ImputationPlanRandomForestExec.scala)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 15:27:23 ERROR ImputationPlan:370 â -------------------------------------
2020-02-10 15:27:23 ERROR ImputationPlan:370 â Running imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
2020-02-10 15:27:23 ERROR ImputationPlan:370 â Missing rate at 30.0% in feature bland_chromatin
2020-02-10 15:27:23 ERROR ImputationPlan:370 â Running Clustering[KMeans] | params: Map(k -> 4, kLimit -> 10, maxIter -> 1000, calcFeatures -> [Ljava.lang.String;@623cd12e)
2020-02-10 15:27:23 ERROR ImputationPlan:370 â ClusteringResult: ClusteringResult(MapPartitionsRDD[94] at map at KMeans.scala:44,4,263.68019710785643)
2020-02-10 15:27:23 ERROR ImputationPlan:370 â best k: 4
2020-02-10 15:27:23 ERROR ImputationPlan:370 â Batch for imputation after clustering strategy: 4
2020-02-10 15:27:23 ERROR ImputationPlan:370 â Batch for imputation before imputation strategy: 4
2020-02-10 15:27:23 ERROR ImputationPlan:370 â Running Imputation[BaggingRegressor] | params: Map(learningRate -> 0.1, k -> 5, imputationFeature -> bland_chromatin, kLimit -> 10, varianceComplete -> 3.9878025896040548, features -> [Ljava.lang.String;@3c81a51a, calcFeatures -> [Ljava.lang.String;@623cd12e)
2020-02-10 15:27:23 ERROR ImputationPlan:371 â Error executing imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:146)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:146)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:122)
	at appraisal.spark.algorithm.BaggingReg.run(BaggingRegressor.scala:112)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:319)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:314)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:314)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:104)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:102)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:102)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:395)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:91)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:89)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.engine.Crowner.runEnsemle(Crowner.scala:89)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec$.main(ImputationPlanRandomForestExec.scala:177)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec.main(ImputationPlanRandomForestExec.scala)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more
2020-02-10 15:27:23 ERROR ImputationPlan:389 â -------------------------------------
2020-02-10 15:27:23 ERROR ImputationPlan:389 â Running imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
2020-02-10 15:27:23 ERROR ImputationPlan:389 â Missing rate at 30.0% in feature bland_chromatin
2020-02-10 15:27:23 ERROR ImputationPlan:389 â Running Clustering[KMeans] | params: Map(k -> 4, kLimit -> 10, maxIter -> 1000, calcFeatures -> [Ljava.lang.String;@623cd12e)
2020-02-10 15:27:23 ERROR ImputationPlan:389 â ClusteringResult: ClusteringResult(MapPartitionsRDD[94] at map at KMeans.scala:44,4,263.68019710785643)
2020-02-10 15:27:23 ERROR ImputationPlan:389 â best k: 4
2020-02-10 15:27:23 ERROR ImputationPlan:389 â Batch for imputation after clustering strategy: 4
2020-02-10 15:27:23 ERROR ImputationPlan:389 â Batch for imputation before imputation strategy: 4
2020-02-10 15:27:23 ERROR ImputationPlan:389 â Running Imputation[BaggingRegressor] | params: Map(learningRate -> 0.1, k -> 5, imputationFeature -> bland_chromatin, kLimit -> 10, varianceComplete -> 3.9878025896040548, features -> [Ljava.lang.String;@3c81a51a, calcFeatures -> [Ljava.lang.String;@623cd12e)
2020-02-10 15:27:23 ERROR ImputationPlan:389 â Total plan execution time: 49 seconds, 0 minutes, 0 hours.
2020-02-10 15:27:23 ERROR Crowner:103 â Executed plans: 1 / 3 : 34%.
2020-02-10 15:27:28 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 15:52:07 ERROR ImputationPlanRandomForestExec$:57 â Appraisal Spark - Wall start time: 10/02/2020 15:52:05
2020-02-10 15:52:07 ERROR ImputationPlanRandomForestExec$:58 â Parallel execution: false
2020-02-10 15:52:12 ERROR ImputationPlanRandomForestExec$:103 â Data count: 146
2020-02-10 16:22:03 ERROR ImputationPlanRandomForestExec$:57 â Appraisal Spark - Wall start time: 10/02/2020 16:22:01
2020-02-10 16:22:03 ERROR ImputationPlanRandomForestExec$:58 â Parallel execution: false
2020-02-10 16:22:11 ERROR ImputationPlanRandomForestExec$:103 â Data count: 146
2020-02-10 16:24:01 ERROR ImputationPlanRandomForestExec$:57 â Appraisal Spark - Wall start time: 10/02/2020 16:24:00
2020-02-10 16:24:01 ERROR ImputationPlanRandomForestExec$:58 â Parallel execution: false
2020-02-10 16:24:07 ERROR ImputationPlanRandomForestExec$:103 â Data count: 146
2020-02-10 21:43:51 ERROR ImputationPlanRandomForestExec$:57 â Appraisal Spark - Wall start time: 10/02/2020 21:43:49
2020-02-10 21:43:51 ERROR ImputationPlanRandomForestExec$:58 â Parallel execution: false
2020-02-10 21:43:58 ERROR ImputationPlanRandomForestExec$:103 â Data count: 146
2020-02-10 21:44:51 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 21:44:51 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:146)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:146)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:122)
	at appraisal.spark.algorithm.BaggingReg.run(BaggingRegressor.scala:112)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:319)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:314)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:314)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:104)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:102)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:102)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:395)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:91)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:89)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.engine.Crowner.runEnsemle(Crowner.scala:89)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec$.main(ImputationPlanRandomForestExec.scala:177)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec.main(ImputationPlanRandomForestExec.scala)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 21:44:51 ERROR ImputationPlan:370 â -------------------------------------
2020-02-10 21:44:51 ERROR ImputationPlan:370 â Running imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
2020-02-10 21:44:51 ERROR ImputationPlan:370 â Missing rate at 30.0% in feature bland_chromatin
2020-02-10 21:44:51 ERROR ImputationPlan:370 â Running Clustering[KMeans] | params: Map(k -> 4, kLimit -> 10, maxIter -> 1000, calcFeatures -> [Ljava.lang.String;@32ff3c98)
2020-02-10 21:44:51 ERROR ImputationPlan:370 â ClusteringResult: ClusteringResult(MapPartitionsRDD[96] at map at KMeans.scala:44,4,258.1181547619044)
2020-02-10 21:44:51 ERROR ImputationPlan:370 â best k: 4
2020-02-10 21:44:51 ERROR ImputationPlan:370 â Batch for imputation after clustering strategy: 4
2020-02-10 21:44:51 ERROR ImputationPlan:370 â Batch for imputation before imputation strategy: 4
2020-02-10 21:44:51 ERROR ImputationPlan:370 â Running Imputation[BaggingRegressor] | params: Map(learningRate -> 0.1, k -> 5, imputationFeature -> bland_chromatin, kLimit -> 10, varianceComplete -> 3.9878025896040548, features -> [Ljava.lang.String;@773e8030, calcFeatures -> [Ljava.lang.String;@32ff3c98)
2020-02-10 21:44:51 ERROR ImputationPlan:371 â Error executing imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$6.apply(CrossValidator.scala:166)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:166)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4.apply(CrossValidator.scala:146)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:146)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1.apply(CrossValidator.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:122)
	at appraisal.spark.algorithm.BaggingReg.run(BaggingRegressor.scala:112)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:319)
	at appraisal.spark.engine.ImputationPlan$$anonfun$13.apply(ImputationPlan.scala:314)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:314)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:104)
	at appraisal.spark.algorithm.Boost$$anonfun$run$3.apply(Boost.scala:102)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:102)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:395)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:91)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$2.apply(Crowner.scala:89)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at appraisal.spark.engine.Crowner.runEnsemle(Crowner.scala:89)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec$.main(ImputationPlanRandomForestExec.scala:177)
	at appraisal.spark.executor.poc.ImputationPlanRandomForestExec.main(ImputationPlanRandomForestExec.scala)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more
2020-02-10 21:44:51 ERROR ImputationPlan:389 â -------------------------------------
2020-02-10 21:44:51 ERROR ImputationPlan:389 â Running imputation plan: Clustering[KMeans]->Imputation[BaggingRegressor]
2020-02-10 21:44:51 ERROR ImputationPlan:389 â Missing rate at 30.0% in feature bland_chromatin
2020-02-10 21:44:51 ERROR ImputationPlan:389 â Running Clustering[KMeans] | params: Map(k -> 4, kLimit -> 10, maxIter -> 1000, calcFeatures -> [Ljava.lang.String;@32ff3c98)
2020-02-10 21:44:51 ERROR ImputationPlan:389 â ClusteringResult: ClusteringResult(MapPartitionsRDD[96] at map at KMeans.scala:44,4,258.1181547619044)
2020-02-10 21:44:51 ERROR ImputationPlan:389 â best k: 4
2020-02-10 21:44:51 ERROR ImputationPlan:389 â Batch for imputation after clustering strategy: 4
2020-02-10 21:44:51 ERROR ImputationPlan:389 â Batch for imputation before imputation strategy: 4
2020-02-10 21:44:51 ERROR ImputationPlan:389 â Running Imputation[BaggingRegressor] | params: Map(learningRate -> 0.1, k -> 5, imputationFeature -> bland_chromatin, kLimit -> 10, varianceComplete -> 3.9878025896040548, features -> [Ljava.lang.String;@773e8030, calcFeatures -> [Ljava.lang.String;@32ff3c98)
2020-02-10 21:44:51 ERROR ImputationPlan:389 â Total plan execution time: 47 seconds, 0 minutes, 0 hours.
2020-02-10 21:44:51 ERROR Crowner:103 â Executed plans: 1 / 3 : 34%.
2020-02-10 21:45:00 ERROR Instrumentation:70 â org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$7.apply(BaggingRegressor.scala:191)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:191)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1.apply(BaggingRegressor.scala:122)
	at org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:121)
	at org.apache.spark.ml.regression.BaggingRegressor.train(BaggingRegressor.scala:81)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:82)
	at org.apache.spark.ml.Estimator.fit(Estimator.scala:61)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply$mcD$sp(CrossValidator.scala:154)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at org.apache.spark.ml.tuning.CrossValidator$$anonfun$fit$1$$anonfun$4$$anonfun$5$$anonfun$apply$1.apply(CrossValidator.scala:153)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: requirement failed: VectorSlicer requires that at least one feature be selected.
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.ml.feature.VectorSlicer.transformSchema(VectorSlicer.scala:147)
	at org.apache.spark.ml.feature.VectorSlicer.transform(VectorSlicer.scala:103)
	at org.apache.spark.ml.ensemble.HasSubBag$class.extractSubBag(HasSubBag.scala:122)
	at org.apache.spark.ml.regression.BaggingRegressor.extractSubBag(BaggingRegressor.scala:81)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2$$anonfun$6.apply(BaggingRegressor.scala:177)
	at org.apache.spark.sql.Dataset.transform(Dataset.scala:2579)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:177)
	at org.apache.spark.ml.regression.BaggingRegressor$$anonfun$train$1$$anonfun$5$$anonfun$apply$2.apply(BaggingRegressor.scala:172)
	... 5 more

2020-02-10 21:49:41 ERROR ImputationPlanRandomForestExec$:57 â Appraisal Spark - Wall start time: 10/02/2020 21:49:39
2020-02-10 21:49:41 ERROR ImputationPlanRandomForestExec$:58 â Parallel execution: false
2020-02-10 21:49:48 ERROR ImputationPlanRandomForestExec$:103 â Data count: 146
