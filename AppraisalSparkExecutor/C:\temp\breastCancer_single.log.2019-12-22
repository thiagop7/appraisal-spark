2019-12-22 15:57:55 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 22/12/2019 15:57:55
2019-12-22 16:03:27 ERROR appraisal:91 â totalError: 19.0
2019-12-22 16:03:27 ERROR appraisal:92 â avgError: 0.13013698630136986
2019-12-22 16:03:27 ERROR appraisal:93 â avgPercentError: 3.881278538812785
2019-12-22 16:03:27 ERROR appraisal:95 â varianceCompleteError: 8.031713267029476
2019-12-22 16:03:27 ERROR AdaboostR2Exec$:105 â ------------------ Wall stop time: 22/12/2019 16:03:27 --- Total wall time: 333 seconds, 5 minutes, 0 hours.
2019-12-22 16:08:17 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 22/12/2019 16:08:17
2019-12-22 16:15:00 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 22/12/2019 16:15:00
2019-12-22 16:19:57 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 22/12/2019 16:19:57
2019-12-22 16:22:35 ERROR appraisal:21 â scala.MatchError: [1.0] (of class org.apache.spark.ml.linalg.DenseVector)
2019-12-22 16:24:44 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 22/12/2019 16:24:44
2019-12-22 16:27:01 ERROR appraisal:21 â scala.MatchError: [1.0] (of class org.apache.spark.ml.linalg.DenseVector)
2019-12-22 16:31:11 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 22/12/2019 16:31:11
2019-12-22 16:39:11 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 22/12/2019 16:39:11
2019-12-22 16:41:20 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 22/12/2019 16:41:20
2019-12-22 16:41:54 ERROR appraisal:91 â totalError: 14.0
2019-12-22 16:41:54 ERROR appraisal:92 â avgError: 0.0958904109589041
2019-12-22 16:41:54 ERROR appraisal:93 â avgPercentError: 2.1404109589041096
2019-12-22 16:41:54 ERROR appraisal:95 â varianceCompleteError: 8.031713267029476
2019-12-22 16:41:54 ERROR AdaboostR2Exec$:105 â ------------------ Wall stop time: 22/12/2019 16:41:54 --- Total wall time: 164 seconds, 2 minutes, 0 hours.
2019-12-22 17:55:57 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 17:55:56
2019-12-22 17:55:57 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 17:56:02 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 17:59:11 ERROR ImputationPlan:312 â -------------------------------------
2019-12-22 17:59:11 ERROR ImputationPlan:312 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 17:59:11 ERROR ImputationPlan:312 â Missing rate at 10.0% in feature single_epithelial_cell_size
2019-12-22 17:59:11 ERROR ImputationPlan:312 â Batch for imputation before imputation strategy: 1
2019-12-22 17:59:11 ERROR ImputationPlan:312 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> single_epithelial_cell_size, kLimit -> 146, varianceComplete -> 7.14374179020453, features -> [Ljava.lang.String;@5cdd9ad6, calcFeatures -> [Ljava.lang.String;@f339a84)
2019-12-22 17:59:11 ERROR ImputationPlan:313 â Error executing imputation plan: Imputation[AdaboostR2]
java.lang.NullPointerException
	at appraisal.spark.algorithm.AdaboostR2.run(AdaboostR2.scala:61)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$7.apply(ImputationPlan.scala:243)
	at appraisal.spark.engine.ImputationPlan$$anonfun$7.apply(ImputationPlan.scala:241)
	at scala.collection.parallel.AugmentedIterableIterator$class.map2combiner(RemainsIterator.scala:115)
	at scala.collection.parallel.immutable.ParVector$ParVectorIterator.map2combiner(ParVector.scala:62)
	at scala.collection.parallel.ParIterableLike$Map.leaf(ParIterableLike.scala:1054)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Map.tryLeaf(ParIterableLike.scala:1051)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$ResultMapping.leaf(ParIterableLike.scala:958)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$ResultMapping.tryLeaf(ParIterableLike.scala:953)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$class.map(ParIterableLike.scala:499)
	at scala.collection.parallel.immutable.ParVector.map(ParVector.scala:38)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:241)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:91)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:89)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$class.foreach(ParIterableLike.scala:463)
	at scala.collection.parallel.immutable.ParVector.foreach(ParVector.scala:38)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:89)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:337)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:71)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:69)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.internal(Tasks.scala:159)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.internal(Tasks.scala:443)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:149)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2019-12-22 17:59:11 ERROR ImputationPlan:331 â -------------------------------------
2019-12-22 17:59:11 ERROR ImputationPlan:331 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 17:59:11 ERROR ImputationPlan:331 â Missing rate at 10.0% in feature single_epithelial_cell_size
2019-12-22 17:59:11 ERROR ImputationPlan:331 â Batch for imputation before imputation strategy: 1
2019-12-22 17:59:11 ERROR ImputationPlan:331 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> single_epithelial_cell_size, kLimit -> 146, varianceComplete -> 7.14374179020453, features -> [Ljava.lang.String;@5cdd9ad6, calcFeatures -> [Ljava.lang.String;@f339a84)
2019-12-22 17:59:11 ERROR ImputationPlan:331 â Total plan execution time: 73 seconds, 1 minutes, 0 hours.
2019-12-22 17:59:11 ERROR Crowner:83 â Executed plans: 1 / 9 : 12%.
2019-12-22 17:59:58 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 17:59:57
2019-12-22 17:59:58 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 18:00:04 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 18:01:38 ERROR ImputationPlan:312 â -------------------------------------
2019-12-22 18:01:38 ERROR ImputationPlan:312 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 18:01:38 ERROR ImputationPlan:312 â Missing rate at 10.0% in feature uniformity_of_cell_shape
2019-12-22 18:01:38 ERROR ImputationPlan:312 â Batch for imputation before imputation strategy: 1
2019-12-22 18:01:38 ERROR ImputationPlan:312 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_shape, kLimit -> 146, varianceComplete -> 7.857055732782882, features -> [Ljava.lang.String;@2d64a62d, calcFeatures -> [Ljava.lang.String;@5f84f259)
2019-12-22 18:01:38 ERROR ImputationPlan:313 â Error executing imputation plan: Imputation[AdaboostR2]
java.lang.NullPointerException
	at appraisal.spark.algorithm.AdaboostR2.run(AdaboostR2.scala:61)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$7.apply(ImputationPlan.scala:243)
	at appraisal.spark.engine.ImputationPlan$$anonfun$7.apply(ImputationPlan.scala:241)
	at scala.collection.parallel.AugmentedIterableIterator$class.map2combiner(RemainsIterator.scala:115)
	at scala.collection.parallel.immutable.ParVector$ParVectorIterator.map2combiner(ParVector.scala:62)
	at scala.collection.parallel.ParIterableLike$Map.leaf(ParIterableLike.scala:1054)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Map.tryLeaf(ParIterableLike.scala:1051)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$ResultMapping.leaf(ParIterableLike.scala:958)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$ResultMapping.tryLeaf(ParIterableLike.scala:953)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$class.map(ParIterableLike.scala:499)
	at scala.collection.parallel.immutable.ParVector.map(ParVector.scala:38)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:241)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:91)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:89)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$class.foreach(ParIterableLike.scala:463)
	at scala.collection.parallel.immutable.ParVector.foreach(ParVector.scala:38)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:89)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:337)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:71)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:69)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.internal(Tasks.scala:159)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.internal(Tasks.scala:443)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:149)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2019-12-22 18:01:38 ERROR ImputationPlan:331 â -------------------------------------
2019-12-22 18:01:38 ERROR ImputationPlan:331 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 18:01:38 ERROR ImputationPlan:331 â Missing rate at 10.0% in feature uniformity_of_cell_shape
2019-12-22 18:01:38 ERROR ImputationPlan:331 â Batch for imputation before imputation strategy: 1
2019-12-22 18:01:38 ERROR ImputationPlan:331 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_shape, kLimit -> 146, varianceComplete -> 7.857055732782882, features -> [Ljava.lang.String;@2d64a62d, calcFeatures -> [Ljava.lang.String;@5f84f259)
2019-12-22 18:01:38 ERROR ImputationPlan:331 â Total plan execution time: 72 seconds, 1 minutes, 0 hours.
2019-12-22 18:01:38 ERROR Crowner:83 â Executed plans: 1 / 9 : 12%.
2019-12-22 18:02:36 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 18:02:34
2019-12-22 18:02:36 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 18:02:43 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 18:16:10 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 18:16:09
2019-12-22 18:16:10 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 18:16:16 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 18:22:47 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 18:22:46
2019-12-22 18:22:47 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 18:22:52 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 18:28:59 ERROR ImputationPlan:320 â -------------------------------------
2019-12-22 18:28:59 ERROR ImputationPlan:320 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 18:28:59 ERROR ImputationPlan:320 â Missing rate at 10.0% in feature bland_chromatin
2019-12-22 18:28:59 ERROR ImputationPlan:320 â Batch for imputation before imputation strategy: 1
2019-12-22 18:28:59 ERROR ImputationPlan:320 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> bland_chromatin, kLimit -> 146, varianceComplete -> 3.9878025896040548, features -> [Ljava.lang.String;@2fdd701a, calcFeatures -> [Ljava.lang.String;@24b52f83)
2019-12-22 18:28:59 ERROR ImputationPlan:320 â ImputationResult: ImputationResult(MapPartitionsRDD[1740] at map at Statistic.scala:16,0,0.18376570514229082,26.829792950774458,4.503292302491107,3.9878025896040548,3.9380048272329597,null,Map(learningRate -> 0.1, k -> 2, imputationFeature -> bland_chromatin, kLimit -> 146, varianceComplete -> 3.9878025896040548, features -> [Ljava.lang.String;@2fdd701a, calcFeatures -> [Ljava.lang.String;@24b52f83))
2019-12-22 18:28:59 ERROR ImputationPlan:320 â best k: 0
2019-12-22 18:28:59 ERROR ImputationPlan:320 â totalError: 26.829792950774458
2019-12-22 18:28:59 ERROR ImputationPlan:320 â avgError: 0.18376570514229082
2019-12-22 18:28:59 ERROR ImputationPlan:320 â avgPercentError: 4.503292302491107
2019-12-22 18:28:59 ERROR ImputationPlan:321 â Error executing imputation plan: Imputation[AdaboostR2]
java.lang.NullPointerException
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:262)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:91)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:89)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$class.foreach(ParIterableLike.scala:463)
	at scala.collection.parallel.immutable.ParVector.foreach(ParVector.scala:38)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:89)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:345)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:71)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:69)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.internal(Tasks.scala:159)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.internal(Tasks.scala:443)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:149)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2019-12-22 18:28:59 ERROR ImputationPlan:339 â -------------------------------------
2019-12-22 18:28:59 ERROR ImputationPlan:339 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 18:28:59 ERROR ImputationPlan:339 â Missing rate at 10.0% in feature bland_chromatin
2019-12-22 18:28:59 ERROR ImputationPlan:339 â Batch for imputation before imputation strategy: 1
2019-12-22 18:28:59 ERROR ImputationPlan:339 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> bland_chromatin, kLimit -> 146, varianceComplete -> 3.9878025896040548, features -> [Ljava.lang.String;@2fdd701a, calcFeatures -> [Ljava.lang.String;@24b52f83)
2019-12-22 18:28:59 ERROR ImputationPlan:339 â ImputationResult: ImputationResult(MapPartitionsRDD[1740] at map at Statistic.scala:16,0,0.18376570514229082,26.829792950774458,4.503292302491107,3.9878025896040548,3.9380048272329597,null,Map(learningRate -> 0.1, k -> 2, imputationFeature -> bland_chromatin, kLimit -> 146, varianceComplete -> 3.9878025896040548, features -> [Ljava.lang.String;@2fdd701a, calcFeatures -> [Ljava.lang.String;@24b52f83))
2019-12-22 18:28:59 ERROR ImputationPlan:339 â best k: 0
2019-12-22 18:28:59 ERROR ImputationPlan:339 â totalError: 26.829792950774458
2019-12-22 18:28:59 ERROR ImputationPlan:339 â avgError: 0.18376570514229082
2019-12-22 18:28:59 ERROR ImputationPlan:339 â avgPercentError: 4.503292302491107
2019-12-22 18:28:59 ERROR ImputationPlan:339 â Total plan execution time: 325 seconds, 5 minutes, 0 hours.
2019-12-22 18:28:59 ERROR Crowner:83 â Executed plans: 1 / 9 : 12%.
2019-12-22 18:32:50 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 18:32:48
2019-12-22 18:32:50 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 18:32:56 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 18:33:06 ERROR ImputationPlan:339 â -------------------------------------
2019-12-22 18:33:06 ERROR ImputationPlan:339 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 18:33:06 ERROR ImputationPlan:339 â Missing rate at 10.0% in feature uniformity_of_cell_size
2019-12-22 18:33:06 ERROR ImputationPlan:339 â Batch for imputation before imputation strategy: 0
2019-12-22 18:33:06 ERROR ImputationPlan:339 â ImputationResult: EMPTY BATCH - There is no tuples for imputation, skiping plan.
2019-12-22 18:33:06 ERROR ImputationPlan:339 â -------------------------------------
2019-12-22 18:33:06 ERROR ImputationPlan:339 â Total plan execution time: 2 seconds, 0 minutes, 0 hours.
2019-12-22 18:33:06 ERROR Crowner:83 â Executed plans: 1 / 9 : 12%.
2019-12-22 18:33:06 ERROR ImputationPlan:339 â -------------------------------------
2019-12-22 18:33:06 ERROR ImputationPlan:339 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 18:33:06 ERROR ImputationPlan:339 â Missing rate at 10.0% in feature marginal_adhesion
2019-12-22 18:33:06 ERROR ImputationPlan:339 â Batch for imputation before imputation strategy: 0
2019-12-22 18:33:06 ERROR ImputationPlan:339 â ImputationResult: EMPTY BATCH - There is no tuples for imputation, skiping plan.
2019-12-22 18:33:06 ERROR ImputationPlan:339 â -------------------------------------
2019-12-22 18:33:06 ERROR ImputationPlan:339 â Total plan execution time: 2 seconds, 0 minutes, 0 hours.
2019-12-22 18:33:06 ERROR Crowner:83 â Executed plans: 2 / 9 : 23%.
2019-12-22 18:34:58 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 18:34:57
2019-12-22 18:34:58 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 18:35:04 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 18:47:18 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 18:47:16
2019-12-22 18:47:18 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 18:47:23 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 18:53:21 ERROR ImputationPlan:320 â -------------------------------------
2019-12-22 18:53:21 ERROR ImputationPlan:320 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 18:53:21 ERROR ImputationPlan:320 â Missing rate at 10.0% in feature uniformity_of_cell_size
2019-12-22 18:53:21 ERROR ImputationPlan:320 â Batch for imputation before imputation strategy: 1
2019-12-22 18:53:21 ERROR ImputationPlan:320 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_size, kLimit -> 146, varianceComplete -> 8.031713267029476, features -> [Ljava.lang.String;@1662b875, calcFeatures -> [Ljava.lang.String;@5b82c496)
2019-12-22 18:53:21 ERROR ImputationPlan:320 â ImputationResult: ImputationResult(MapPartitionsRDD[1243] at map at Statistic.scala:16,0,0.0410958904109589,6.0,2.6255707762557075,8.031713267029476,7.930645411728182,null,Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_size, kLimit -> 146, varianceComplete -> 8.031713267029476, features -> [Ljava.lang.String;@1662b875, calcFeatures -> [Ljava.lang.String;@5b82c496))
2019-12-22 18:53:21 ERROR ImputationPlan:320 â best k: 0
2019-12-22 18:53:21 ERROR ImputationPlan:320 â totalError: 6.0
2019-12-22 18:53:21 ERROR ImputationPlan:320 â avgError: 0.0410958904109589
2019-12-22 18:53:21 ERROR ImputationPlan:320 â avgPercentError: 2.6255707762557075
2019-12-22 18:53:21 ERROR ImputationPlan:321 â Error executing imputation plan: Imputation[AdaboostR2]
java.lang.NullPointerException
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:262)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:91)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:89)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$class.foreach(ParIterableLike.scala:463)
	at scala.collection.parallel.immutable.ParVector.foreach(ParVector.scala:38)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:89)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:345)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:71)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:69)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2019-12-22 18:53:21 ERROR ImputationPlan:339 â -------------------------------------
2019-12-22 18:53:21 ERROR ImputationPlan:339 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 18:53:21 ERROR ImputationPlan:339 â Missing rate at 10.0% in feature uniformity_of_cell_size
2019-12-22 18:53:21 ERROR ImputationPlan:339 â Batch for imputation before imputation strategy: 1
2019-12-22 18:53:21 ERROR ImputationPlan:339 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_size, kLimit -> 146, varianceComplete -> 8.031713267029476, features -> [Ljava.lang.String;@1662b875, calcFeatures -> [Ljava.lang.String;@5b82c496)
2019-12-22 18:53:21 ERROR ImputationPlan:339 â ImputationResult: ImputationResult(MapPartitionsRDD[1243] at map at Statistic.scala:16,0,0.0410958904109589,6.0,2.6255707762557075,8.031713267029476,7.930645411728182,null,Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_size, kLimit -> 146, varianceComplete -> 8.031713267029476, features -> [Ljava.lang.String;@1662b875, calcFeatures -> [Ljava.lang.String;@5b82c496))
2019-12-22 18:53:21 ERROR ImputationPlan:339 â best k: 0
2019-12-22 18:53:21 ERROR ImputationPlan:339 â totalError: 6.0
2019-12-22 18:53:21 ERROR ImputationPlan:339 â avgError: 0.0410958904109589
2019-12-22 18:53:21 ERROR ImputationPlan:339 â avgPercentError: 2.6255707762557075
2019-12-22 18:53:21 ERROR ImputationPlan:339 â Total plan execution time: 324 seconds, 5 minutes, 0 hours.
2019-12-22 18:53:21 ERROR Crowner:83 â Executed plans: 1 / 9 : 12%.
2019-12-22 18:53:53 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 18:53:51
2019-12-22 18:53:53 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 18:53:57 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 19:05:08 ERROR ImputationPlan:320 â -------------------------------------
2019-12-22 19:05:08 ERROR ImputationPlan:320 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 19:05:08 ERROR ImputationPlan:320 â Missing rate at 10.0% in feature uniformity_of_cell_shape
2019-12-22 19:05:08 ERROR ImputationPlan:320 â Batch for imputation before imputation strategy: 1
2019-12-22 19:05:08 ERROR ImputationPlan:320 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_shape, kLimit -> 146, varianceComplete -> 7.857055732782882, features -> [Ljava.lang.String;@49cffc01, calcFeatures -> [Ljava.lang.String;@416f8e22)
2019-12-22 19:05:08 ERROR ImputationPlan:320 â ImputationResult: ImputationResult(MapPartitionsRDD[1246] at map at Statistic.scala:16,0,0.18493150684931506,27.0,3.8747553816046962,7.857055732782882,7.441449717923492,null,Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_shape, kLimit -> 146, varianceComplete -> 7.857055732782882, features -> [Ljava.lang.String;@49cffc01, calcFeatures -> [Ljava.lang.String;@416f8e22))
2019-12-22 19:05:08 ERROR ImputationPlan:320 â best k: 0
2019-12-22 19:05:08 ERROR ImputationPlan:320 â totalError: 27.0
2019-12-22 19:05:08 ERROR ImputationPlan:320 â avgError: 0.18493150684931506
2019-12-22 19:05:08 ERROR ImputationPlan:320 â avgPercentError: 3.8747553816046962
2019-12-22 19:05:08 ERROR ImputationPlan:321 â Error executing imputation plan: Imputation[AdaboostR2]
java.lang.NullPointerException
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:262)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:91)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:89)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$class.foreach(ParIterableLike.scala:463)
	at scala.collection.parallel.immutable.ParVector.foreach(ParVector.scala:38)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:89)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:345)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:71)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:69)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.internal(Tasks.scala:159)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.internal(Tasks.scala:443)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:149)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2019-12-22 19:05:08 ERROR ImputationPlan:339 â -------------------------------------
2019-12-22 19:05:08 ERROR ImputationPlan:339 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 19:05:08 ERROR ImputationPlan:339 â Missing rate at 10.0% in feature uniformity_of_cell_shape
2019-12-22 19:05:08 ERROR ImputationPlan:339 â Batch for imputation before imputation strategy: 1
2019-12-22 19:05:08 ERROR ImputationPlan:339 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_shape, kLimit -> 146, varianceComplete -> 7.857055732782882, features -> [Ljava.lang.String;@49cffc01, calcFeatures -> [Ljava.lang.String;@416f8e22)
2019-12-22 19:05:08 ERROR ImputationPlan:339 â ImputationResult: ImputationResult(MapPartitionsRDD[1246] at map at Statistic.scala:16,0,0.18493150684931506,27.0,3.8747553816046962,7.857055732782882,7.441449717923492,null,Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_shape, kLimit -> 146, varianceComplete -> 7.857055732782882, features -> [Ljava.lang.String;@49cffc01, calcFeatures -> [Ljava.lang.String;@416f8e22))
2019-12-22 19:05:08 ERROR ImputationPlan:339 â best k: 0
2019-12-22 19:05:08 ERROR ImputationPlan:339 â totalError: 27.0
2019-12-22 19:05:08 ERROR ImputationPlan:339 â avgError: 0.18493150684931506
2019-12-22 19:05:08 ERROR ImputationPlan:339 â avgPercentError: 3.8747553816046962
2019-12-22 19:05:08 ERROR ImputationPlan:339 â Total plan execution time: 663 seconds, 11 minutes, 0 hours.
2019-12-22 19:05:08 ERROR Crowner:83 â Executed plans: 1 / 9 : 12%.
2019-12-22 19:06:12 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 19:06:11
2019-12-22 19:06:12 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 19:06:17 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 19:11:56 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 19:11:54
2019-12-22 19:11:56 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 19:12:01 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 19:15:19 ERROR ImputationPlan:339 â -------------------------------------
2019-12-22 19:15:19 ERROR ImputationPlan:339 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 19:15:19 ERROR ImputationPlan:339 â Missing rate at 10.0% in feature uniformity_of_cell_size
2019-12-22 19:15:19 ERROR ImputationPlan:339 â Batch for imputation before imputation strategy: 1
2019-12-22 19:15:19 ERROR ImputationPlan:339 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_size, kLimit -> 146, varianceComplete -> 8.031713267029476, features -> [Ljava.lang.String;@6c94b801, calcFeatures -> [Ljava.lang.String;@313e46bd)
2019-12-22 19:15:19 ERROR ImputationPlan:339 â ImputationResult: ImputationResult(MapPartitionsRDD[991] at map at Statistic.scala:16,0,0.14383561643835616,21.0,4.220482713633398,8.031713267029476,7.641685212980669,null,Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_size, kLimit -> 146, varianceComplete -> 8.031713267029476, features -> [Ljava.lang.String;@6c94b801, calcFeatures -> [Ljava.lang.String;@313e46bd))
2019-12-22 19:15:19 ERROR ImputationPlan:339 â best k: 0
2019-12-22 19:15:19 ERROR ImputationPlan:339 â totalError: 21.0
2019-12-22 19:15:19 ERROR ImputationPlan:339 â avgError: 0.14383561643835616
2019-12-22 19:15:19 ERROR ImputationPlan:339 â avgPercentError: 4.220482713633398
2019-12-22 19:15:19 ERROR ImputationPlan:339 â varianceCompleteError: 8.031713267029476
2019-12-22 19:15:19 ERROR ImputationPlan:339 â -------------------------------------
2019-12-22 19:15:19 ERROR ImputationPlan:339 â Total plan execution time: 160 seconds, 2 minutes, 0 hours.
2019-12-22 19:16:48 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 19:16:46
2019-12-22 19:16:48 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 19:16:53 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 19:22:12 ERROR ImputationPlan:341 â -------------------------------------
2019-12-22 19:22:12 ERROR ImputationPlan:341 â Running imputation plan: Imputation[AdaboostR2]
2019-12-22 19:22:12 ERROR ImputationPlan:341 â Missing rate at 10.0% in feature normal_nucleoli
2019-12-22 19:22:12 ERROR ImputationPlan:341 â Batch for imputation before imputation strategy: 1
2019-12-22 19:22:12 ERROR ImputationPlan:341 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> normal_nucleoli, kLimit -> 146, varianceComplete -> 9.0838806530306, features -> [Ljava.lang.String;@11a05c67, calcFeatures -> [Ljava.lang.String;@3b34162f)
2019-12-22 19:22:12 ERROR ImputationPlan:341 â ImputationResult: ImputationResult(MapPartitionsRDD[1296] at map at Statistic.scala:16,0,0.7302293205850752,106.61348080542098,60.25246061370719,9.0838806530306,10.83954656473415,null,Map(learningRate -> 0.1, k -> 2, imputationFeature -> normal_nucleoli, kLimit -> 146, varianceComplete -> 9.0838806530306, features -> [Ljava.lang.String;@11a05c67, calcFeatures -> [Ljava.lang.String;@3b34162f))
2019-12-22 19:22:12 ERROR ImputationPlan:341 â best k: 0
2019-12-22 19:22:12 ERROR ImputationPlan:341 â totalError: 106.61348080542098
2019-12-22 19:22:12 ERROR ImputationPlan:341 â avgError: 0.7302293205850752
2019-12-22 19:22:12 ERROR ImputationPlan:341 â avgPercentError: 60.25246061370719
2019-12-22 19:22:12 ERROR ImputationPlan:341 â varianceCompleteError: 9.0838806530306
2019-12-22 19:22:12 ERROR ImputationPlan:341 â varianceImputedError: 10.83954656473415
2019-12-22 19:22:12 ERROR ImputationPlan:341 â -------------------------------------
2019-12-22 19:22:12 ERROR ImputationPlan:341 â Total plan execution time: 310 seconds, 5 minutes, 0 hours.
2019-12-22 19:22:12 ERROR Crowner:83 â Executed plans: 1 / 2 : 50%.
2019-12-22 19:34:59 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 19:34:58
2019-12-22 19:34:59 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 19:35:04 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 19:38:32 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 19:38:30
2019-12-22 19:38:32 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 19:38:37 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 19:40:45 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 22/12/2019 19:40:44
2019-12-22 19:40:45 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-22 19:40:51 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-22 19:47:39 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 22/12/2019 19:47:39
