2019-12-23 16:10:12 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 16:10:12
2019-12-23 16:14:20 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 23/12/2019 16:14:18
2019-12-23 16:14:20 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-23 16:14:24 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-23 16:19:04 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 23/12/2019 16:19:02
2019-12-23 16:19:04 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-23 16:19:09 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-23 16:19:50 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 23/12/2019 16:19:48
2019-12-23 16:19:50 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-23 16:19:54 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-23 16:23:43 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 23/12/2019 16:23:41
2019-12-23 16:23:43 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-23 16:23:49 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-23 16:29:05 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 16:29:05
2019-12-23 16:31:02 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 16:31:02
2019-12-23 16:32:46 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 23/12/2019 16:32:45
2019-12-23 16:32:46 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-23 16:32:51 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-23 16:35:22 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 16:35:22
2019-12-23 16:37:58 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 23/12/2019 16:37:57
2019-12-23 16:37:58 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-23 16:38:03 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-23 16:46:32 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 16:46:32
2019-12-23 16:48:48 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 16:48:48
2019-12-23 16:49:37 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 23/12/2019 16:49:35
2019-12-23 16:49:37 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-23 16:49:42 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-23 16:54:16 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 23/12/2019 16:54:15
2019-12-23 16:54:16 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-23 16:54:21 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-23 17:15:45 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 17:15:45
2019-12-23 17:21:48 ERROR appraisal:21 â java.lang.IllegalArgumentException: requirement failed: subModels not available, To retrieve subModels, make sure to set collectSubModels to true before fitting.
2019-12-23 18:25:49 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 18:25:49
2019-12-23 18:25:55 ERROR ImputationPlanAdaboostR2Exec$:58 â Appraisal Spark - Wall start time: 23/12/2019 18:25:54
2019-12-23 18:25:55 ERROR ImputationPlanAdaboostR2Exec$:59 â Parallel execution: true
2019-12-23 18:26:02 ERROR ImputationPlanAdaboostR2Exec$:104 â Data count: 146
2019-12-23 18:32:04 ERROR ImputationPlan:321 â -------------------------------------
2019-12-23 18:32:04 ERROR ImputationPlan:321 â Running imputation plan: Imputation[AdaboostR2]
2019-12-23 18:32:04 ERROR ImputationPlan:321 â Missing rate at 10.0% in feature marginal_adhesion
2019-12-23 18:32:04 ERROR ImputationPlan:321 â Batch for imputation before imputation strategy: 1
2019-12-23 18:32:04 ERROR ImputationPlan:321 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> marginal_adhesion, kLimit -> 146, varianceComplete -> 7.177190842559583, features -> [Ljava.lang.String;@4edcafe4, calcFeatures -> [Ljava.lang.String;@4a21a62a)
2019-12-23 18:32:04 ERROR ImputationPlan:322 â Error executing imputation plan: Imputation[AdaboostR2]
java.lang.ClassCastException: org.apache.spark.ml.regression.DecisionTreeRegressionModel cannot be cast to org.apache.spark.ml.regression.BoostingRegressionModel
	at appraisal.spark.algorithm.AdaboostR2$$anonfun$6.apply(AdaboostR2.scala:131)
	at appraisal.spark.algorithm.AdaboostR2$$anonfun$6.apply(AdaboostR2.scala:130)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at appraisal.spark.algorithm.AdaboostR2.run(AdaboostR2.scala:130)
	at appraisal.spark.strategies.ImputationStrategy.run(ImputationStrategy.scala:12)
	at appraisal.spark.engine.ImputationPlan$$anonfun$8.apply(ImputationPlan.scala:250)
	at appraisal.spark.engine.ImputationPlan$$anonfun$8.apply(ImputationPlan.scala:248)
	at scala.collection.parallel.AugmentedIterableIterator$class.map2combiner(RemainsIterator.scala:115)
	at scala.collection.parallel.immutable.ParVector$ParVectorIterator.map2combiner(ParVector.scala:62)
	at scala.collection.parallel.ParIterableLike$Map.leaf(ParIterableLike.scala:1054)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Map.tryLeaf(ParIterableLike.scala:1051)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$ResultMapping.leaf(ParIterableLike.scala:958)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$ResultMapping.tryLeaf(ParIterableLike.scala:953)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$class.map(ParIterableLike.scala:499)
	at scala.collection.parallel.immutable.ParVector.map(ParVector.scala:38)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:248)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:90)
	at appraisal.spark.algorithm.Boost$$anonfun$run$2.apply(Boost.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$class.foreach(ParIterableLike.scala:463)
	at scala.collection.parallel.immutable.ParVector.foreach(ParVector.scala:38)
	at appraisal.spark.algorithm.Boost.run(Boost.scala:88)
	at appraisal.spark.strategies.EnsembleStrategy.run(EnsembleStrategy.scala:11)
	at appraisal.spark.engine.ImputationPlan.run(ImputationPlan.scala:346)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:71)
	at appraisal.spark.engine.Crowner$$anonfun$runEnsemle$1.apply(Crowner.scala:69)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2019-12-23 18:32:04 ERROR ImputationPlan:340 â -------------------------------------
2019-12-23 18:32:04 ERROR ImputationPlan:340 â Running imputation plan: Imputation[AdaboostR2]
2019-12-23 18:32:04 ERROR ImputationPlan:340 â Missing rate at 10.0% in feature marginal_adhesion
2019-12-23 18:32:04 ERROR ImputationPlan:340 â Batch for imputation before imputation strategy: 1
2019-12-23 18:32:04 ERROR ImputationPlan:340 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> marginal_adhesion, kLimit -> 146, varianceComplete -> 7.177190842559583, features -> [Ljava.lang.String;@4edcafe4, calcFeatures -> [Ljava.lang.String;@4a21a62a)
2019-12-23 18:32:04 ERROR ImputationPlan:340 â Total plan execution time: 351 seconds, 5 minutes, 0 hours.
2019-12-23 18:32:04 ERROR Crowner:83 â Executed plans: 1 / 9 : 12%.
2019-12-23 18:34:27 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 18:34:27
2019-12-23 18:39:19 ERROR appraisal:94 â totalError: 9.0
2019-12-23 18:39:19 ERROR appraisal:95 â avgError: 0.06164383561643835
2019-12-23 18:39:19 ERROR appraisal:96 â avgPercentError: 1.004566210045662
2019-12-23 18:39:19 ERROR appraisal:98 â varianceCompleteError: 8.031713267029476
2019-12-23 18:39:19 ERROR AdaboostR2Exec$:108 â ------------------ Wall stop time: 23/12/2019 18:39:19 --- Total wall time: 294 seconds, 4 minutes, 0 hours.
2019-12-23 18:46:56 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 18:46:56
2019-12-23 18:50:32 ERROR appraisal:94 â totalError: 0.0
2019-12-23 18:50:32 ERROR appraisal:95 â avgError: 0.0
2019-12-23 18:50:32 ERROR appraisal:96 â avgPercentError: 0.0
2019-12-23 18:50:32 ERROR appraisal:98 â varianceCompleteError: 8.031713267029476
2019-12-23 18:50:32 ERROR AdaboostR2Exec$:108 â ------------------ Wall stop time: 23/12/2019 18:50:32 --- Total wall time: 218 seconds, 3 minutes, 0 hours.
2019-12-23 18:54:44 ERROR AdaboostR2Exec$:19 â Appraisal Spark - Wall start time: 23/12/2019 18:54:44
2019-12-23 18:58:36 ERROR appraisal:94 â totalError: 0.18505830254940134
2019-12-23 18:58:36 ERROR appraisal:95 â avgError: 0.0
2019-12-23 18:58:36 ERROR appraisal:96 â avgPercentError: 0.224038958895696
2019-12-23 18:58:36 ERROR appraisal:97 â varianceImputedError: 8.18472128771802
2019-12-23 18:58:36 ERROR appraisal:98 â varianceCompleteError: 8.031713267029476
2019-12-23 18:58:36 ERROR AdaboostR2Exec$:108 â ------------------ Wall stop time: 23/12/2019 18:58:36 --- Total wall time: 234 seconds, 3 minutes, 0 hours.
2019-12-23 19:05:16 ERROR ImputationPlanAdaboostR2Exec$:57 â Appraisal Spark - Wall start time: 23/12/2019 19:05:13
2019-12-23 19:05:16 ERROR ImputationPlanAdaboostR2Exec$:58 â Parallel execution: true
2019-12-23 19:05:25 ERROR ImputationPlanAdaboostR2Exec$:103 â Data count: 146
2019-12-23 19:11:16 ERROR ImputationPlan:340 â -------------------------------------
2019-12-23 19:11:16 ERROR ImputationPlan:340 â Running imputation plan: Imputation[AdaboostR2]
2019-12-23 19:11:16 ERROR ImputationPlan:340 â Missing rate at 10.0% in feature uniformity_of_cell_shape
2019-12-23 19:11:16 ERROR ImputationPlan:340 â Batch for imputation before imputation strategy: 1
2019-12-23 19:11:16 ERROR ImputationPlan:340 â Running Imputation[AdaboostR2] | params: Map(learningRate -> 0.1, k -> 2, imputationFeature -> uniformity_of_cell_shape, kLimit -> 146, varianceComplete -> 7.857055732782882, features -> [Ljava.lang.String;@24662b44, calcFeatures -> [Ljava.lang.String;@610e9614)
2019-12-23 19:11:16 ERROR ImputationPlan:340 â ImputationResult: ImputationResult(MapPartitionsRDD[1755] at map at Statistic.scala:16,0,0.0,0.8023936792113684,0.6420947917823132,7.857055732782882,7.517312768490254,null,4.650143551630823)
2019-12-23 19:11:16 ERROR ImputationPlan:340 â best k: 0
2019-12-23 19:11:16 ERROR ImputationPlan:340 â totalError: 0.8023936792113684
2019-12-23 19:11:16 ERROR ImputationPlan:340 â avgError: 0.0
2019-12-23 19:11:16 ERROR ImputationPlan:340 â avgPercentError: 0.6420947917823132
2019-12-23 19:11:16 ERROR ImputationPlan:340 â varianceCompleteError: 7.857055732782882
2019-12-23 19:11:16 ERROR ImputationPlan:340 â varianceImputedError: 7.517312768490254
2019-12-23 19:11:16 ERROR ImputationPlan:340 â -------------------------------------
2019-12-23 19:11:16 ERROR ImputationPlan:340 â Total plan execution time: 345 seconds, 5 minutes, 0 hours.
2019-12-23 19:11:16 ERROR Crowner:83 â Executed plans: 1 / 2 : 50%.
2019-12-23 19:21:24 ERROR ImputationPlanAdaboostR2Exec$:57 â Appraisal Spark - Wall start time: 23/12/2019 19:21:22
2019-12-23 19:21:24 ERROR ImputationPlanAdaboostR2Exec$:58 â Parallel execution: true
2019-12-23 19:21:32 ERROR ImputationPlanAdaboostR2Exec$:103 â Data count: 146
2019-12-23 19:35:21 ERROR ImputationPlanAdaboostR2Exec$:57 â Appraisal Spark - Wall start time: 23/12/2019 19:35:17
2019-12-23 19:35:21 ERROR ImputationPlanAdaboostR2Exec$:58 â Parallel execution: true
2019-12-23 19:35:31 ERROR ImputationPlanAdaboostR2Exec$:103 â Data count: 146
